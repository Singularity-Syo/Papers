

[1] Waleed Abdulla. Splash of Color: Instance Segmen-tation with Mask R-CNN and TensorFlow, 2018.
https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46.

[2] Roee Aharoni, Melvin Johnson, and Orhan Firat.Massively multilingual neural machine translation.arXiv preprint 
arXiv:1903.00089, 2019.

[3] JayAlammar.TheIllustratedTransformer,2018.
http://jalammar.github.io/illustrated-transformer/.

[4] Mohsan Alvi, Andrew Zisserman, and ChristofferNellåker. Turning a blind eye: Explicit removal ofbiases and variation from deep neural network em-beddings. In Proceedings of the European Conferenceon Computer Vision (ECCV), pages 0–0, 2018.

[5] Marios Anthimopoulos, Stergios Christodoulidis,Lukas Ebner, Andreas Christe, and StavroulaMougiakakou.Lung pattern classification for in-terstitial lung diseases using a deep convolutionalneural network. IEEE transactions on medical imag-ing, 35(5):1207–1216, 2016.

[6] Sebastian Bach, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller,and Wojciech Samek. On pixel-wise explanations for non-linear classifier decisions by layer-wise relevancepropagation. PloS one, 10(7):e0130140, 2015.

[7] Philip Bachman, R Devon Hjelm, and William Buch-walter.Learning representations by maximizingmutual information across views. arXiv preprintarXiv:1906.00910, 2019.

[8] Marcus A Badgeley, John R Zech, Luke Oakden-Rayner, Benjamin S Glicksberg, Manway Liu,William Gale, Michael V McConnell, Bethany Per-cha, Thomas M Snyder, and Joel T Dudley. Deeplearning predicts hip fracture using confounding pa-tient and healthcare variables. npj Digital Medicine,2(1):31, 2019.

[9] Vijay Badrinarayanan, Alex Kendall, and RobertoCipolla.Segnet: A deep convolutional encoder-decoder architecture for image segmentation. IEEEtransactions on pattern analysis and machine intel-ligence, 39(12):2481–2495, 2017.

[10] Dzmitry Bahdanau, Kyunghyun Cho, and YoshuaBengio.Neural machine translation by jointlylearning to align and translate.arXiv preprintarXiv:1409.0473, 2014.

[11] Dzmitry Bahdanau,JanChorowski,DmitriySerdyuk, Philemon Brakel, and Yoshua Bengio.End-to-end attention-based large vocabulary speechrecognition. In 2016 IEEE international conferenceon acoustics, speech and signal processing (ICASSP),pages 4945–4949. IEEE, 2016.

[12] Guha Balakrishnan, Amy Zhao, Mert R Sabuncu,John Guttag, and Adrian V Dalca. An unsuper-vised learning model for deformable medical imageregistration. In Proceedings of the IEEE conferenceon computer vision and pattern recognition, pages9252–9260, 2018.

[13] Guha Balakrishnan, Amy Zhao, Mert R Sabuncu,John Guttag, and Adrian V Dalca. Voxelmorph: alearning framework for deformable medical imageregistration. IEEE transactions on medical imaging,2019.

[14] Joshua Batson and Loic Royer. Noise2self: Blinddenoising by self-supervision.arXiv preprintarXiv:1901.11365, 2019.

[15] Peter Battaglia, Razvan Pascanu, Matthew Lai,Danilo Jimenez Rezende, et al. Interaction networksfor learning about objects, relations and physics. InAdvances in neural information processing systems,pages 4502–4510, 2016.

[16] Anthony Bau,Yonatan Belinkov,Hassan Saj-jad, Nadir Durrani, Fahim Dalvi, and JamesGlass. Identifying and controlling important neu-rons in neural machine translation. arXiv preprintarXiv:1811.01157, 2018.

[17] David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva,and Antonio Torralba. Network dissection: Quanti-fying interpretability of deep visual representations.In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition, pages 6541–6549,2017.

[18] Iz Beltagy, Arman Cohan, and Kyle Lo. Scibert:Pretrained contextualized embeddings for scientifictext. arXiv preprint arXiv:1903.10676, 2019.

[19] David Berthelot, Nicholas Carlini, Ian Goodfellow,Nicolas Papernot, Avital Oliver, and Colin Raffel.Mixmatch: A holistic approach to semi-supervisedlearning. arXiv preprint arXiv:1905.02249, 2019.

[20] Mariusz Bojarski, Anna Choromanska, KrzysztofChoromanski, Bernhard Firner, Larry Jackel, UrsMuller, and Karol Zieba. Visualbackprop: visual-izing cnns for autonomous driving. arXiv preprintarXiv:1611.05418, 2, 2016.

[21] Xavier Bresson and Thomas Laurent. A two-stepgraph convolutional decoder for molecule generation.arXiv preprint arXiv:1906.03412, 2019.

[22] Andrew Brock, Jeff Donahue, and Karen Simonyan.Large scale gan training for high fidelity naturalimage synthesis. arXiv preprint arXiv:1809.11096,2018.

[23] Renzhi Cao, Colton Freitas, Leong Chan, MiaoSun, Haiqing Jiang, and Zhangxin Chen. Prolango:protein function prediction using neural machinetranslation based on a recurrent neural network.Molecules, 22(10):1732, 2017.

[24] Zhe Cao, Gines Hidalgo, Tomas Simon, Shih-En Wei,and Yaser Sheikh. OpenPose: realtime multi-person2D pose estimation using Part Affinity Fields. InarXiv preprint arXiv:1812.08008, 2018.

[25] Brandon Carter, Jonas Mueller, Siddhartha Jain,and David Gifford. What made you do this? under-standing black-box decisions with sufficient inputsubsets. arXiv preprint arXiv:1810.03805, 2018.

[26] Shan Carter, Zan Armstrong, Ludwig Schubert, IanJohnson, and Chris Olah. Activation atlas. Distill,2019. https://distill.pub/2019/activation-atlas.

[27] Caroline Chan, Shiry Ginosar, Tinghui Zhou, andAlexei A Efros.Everybody dance now.In Pro-ceedings of the IEEE International Conference onComputer Vision, pages 5933–5942, 2019.

[28] Danqi Chen and Christopher Manning. A fast andaccurate dependency parser using neural networks.In Proceedings of the 2014 conference on empiricalmethods in natural language processing (EMNLP),pages 740–750, 2014.

[29] Ting Chen, Simon Kornblith, Mohammad Norouzi,and Geoffrey Hinton. A simple framework for con-trastive learning of visual representations. arXivpreprint arXiv:2002.05709, 2020.

[30] Ting Chen, Yizhou Sun, Yue Shi, and Liangjie Hong.On sampling strategies for neural network-based col-laborative filtering. In Proceedings of the 23rd ACMSIGKDD International Conference on KnowledgeDiscovery and Data Mining, pages 767–776, 2017.

[31] Yuhua Chen, Yibin Xie, Zhengwei Zhou, Feng Shi,Anthony G Christodoulou, and Debiao Li. Brainmri super resolution using 3d deep densely con-nected neural networks. In 2018 IEEE 15th Inter-national Symposium on Biomedical Imaging (ISBI2018), pages 739–742. IEEE, 2018.

[32] Jan K Chorowski, Dzmitry Bahdanau, DmitriySerdyuk, Kyunghyun Cho, and Yoshua Bengio.Attention-based models for speech recognition. InAdvances in neural information processing systems,pages 577–585, 2015.

[33] ÖzgünÇiçek,AhmedAbdulkadir,SoerenSLienkamp, Thomas Brox, and Olaf Ronneberger.3d u-net: learning dense volumetric segmentationfrom sparse annotation. In International conferenceon medical image computing and computer-assistedintervention, pages 424–432. Springer, 2016.

[34] Kevin Clark, Minh-Thang Luong, Christopher DManning, and Quoc V Le. Semi-supervised sequencemodeling with cross-view training. arXiv preprintarXiv:1809.08370, 2018.

[35] Taco Cohen and Max Welling. Group equivariantconvolutional networks. In International conferenceon machine learning, pages 2990–2999, 2016.

[36] Taco S Cohen, Mario Geiger, Jonas Köhler, andMax Welling.Spherical cnns.arXiv preprintarXiv:1801.10130, 2018.

[37] Peter Corbett and John Boyle. Improving the learn-ing of chemical-protein interactions from literatureusing transfer learning and specialized word embed-dings. Database, 2018, 2018.

[38] Ekin D Cubuk, Barret Zoph, Jonathon Shlens, andQuoc V Le.Randaugment: Practical data aug-mentation with no separate search. arXiv preprintarXiv:1909.13719, 2019.

[39] Adrian Dalca, Marianne Rakic, John Guttag, andMert Sabuncu.Learning conditional deformabletemplates with convolutional networks. In Advancesin neural information processing systems, pages 804–816, 2019.

[40] Yann Dauphin. mixup: Beyond Empirical Risk Min-imization Image, 2017. https://www.dauphin.io/.

[41] Nicola De Cao and Thomas Kipf. Molgan: Animplicit generative model for small molecular graphs.arXiv preprint arXiv:1805.11973, 2018.

[42] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, KaiLi, and Li Fei-Fei. Imagenet: A large-scale hierar-chical image database. In 2009 IEEE conferenceon computer vision and pattern recognition, pages248–255. Ieee, 2009.

[43] Jacob Devlin, Ming-Wei Chang, Kenton Lee, andKristina Toutanova. Bert: Pre-training of deep bidi-rectional transformers for language understanding.arXiv preprint arXiv:1810.04805, 2018.

[44] Terrance DeVries and Graham W Taylor. Improvedregularization of convolutional neural networks withcutout. arXiv preprint arXiv:1708.04552, 2017.

[45] Yiming Ding, Jae Ho Sohn, Michael G Kawczynski,Hari Trivedi, Roy Harnish, Nathaniel W Jenkins,Dmytro Lituiev, Timothy P Copeland, Mariam SAboian, Carina Mari Aparici, et al. A deep learningmodel to predict a diagnosis of alzheimer disease byusing 18f-fdg pet of the brain. Radiology, 290(2):456–464, 2018.

[46] Laurent Dinh, David Krueger, and Yoshua Bengio.Nice: Non-linear independent components estima-tion. arXiv preprint arXiv:1410.8516, 2014.

[47] Laurent Dinh, Jascha Sohl-Dickstein, and SamyBengio. Density estimation using real nvp. arXivpreprint arXiv:1605.08803, 2016.

[48] Carl Doersch, Abhinav Gupta, and Alexei A Efros.Unsupervised visual representation learning by con-text prediction.In Proceedings of the IEEE In-ternational Conference on Computer Vision, pages1422–1430, 2015.

[49] Jeff Donahue and Karen Simonyan.Large scaleadversarial representation learning.In Advancesin Neural Information Processing Systems, pages10541–10551, 2019.

[50] Chao Dong, Chen Change Loy, Kaiming He, andXiaoou Tang. Image super-resolution using deep con-volutional networks. IEEE transactions on patternanalysis and machine intelligence, 38(2):295–307,2015.

[51] Alexey Dosovitskiy, Jost Tobias Springenberg, Mar-tin Riedmiller, and Thomas Brox. Discriminativeunsupervised feature learning with convolutionalneural networks. In Advances in neural informationprocessing systems, pages 766–774, 2014.

[52] Yong Du, Wei Wang, and Liang Wang. Hierarchicalrecurrent neural network for skeleton based actionrecognition. In Proceedings of the IEEE conferenceon computer vision and pattern recognition, pages1110–1118, 2015.

[53] David K Duvenaud, Dougal Maclaurin, Jorge Ipar-raguirre, Rafael Bombarell, Timothy Hirzel, AlánAspuru-Guzik, and Ryan P Adams. Convolutionalnetworks on graphs for learning molecular finger-prints. In Advances in neural information processingsystems, pages 2224–2232, 2015.

[54] Sergey Edunov, Myle Ott, Michael Auli, and DavidGrangier. Understanding back-translation at scale.arXiv preprint arXiv:1808.09381, 2018.

[55] Andre Esteva, Brett Kuprel, Roberto A Novoa,Justin Ko, Susan M Swetter, Helen M Blau, andSebastian Thrun. Dermatologist-level classificationof skin cancer with deep neural networks. Nature,542(7639):115, 2017.

[56] Linjing Fang, Fred Monroe, Sammy Weiser Novak,Lyndsey Kirk, Cara R Schiavon, B Yu Seungyoon,Tong Zhang, Melissa Wu, Kyle Kastner, YoshiyukiKubota, et al. Deep learning-based point-scanningsuper-resolution imaging.bioRxiv, page 740548,2019.

[57] Chelsea Finn, Ian Goodfellow, and Sergey Levine.Unsupervised learning for physical interactionthrough video prediction. In Advances in neuralinformation processing systems, pages 64–72, 2016.

[58] Marc Finzi, Samuel Stanton, Pavel Izmailov, andAndrew Gordon Wilson.Generalizing convolu-tional neural networks for equivariance to lie groupson arbitrary continuous data.arXiv preprintarXiv:2002.12880, 2020.

[59] Ruth C Fong and Andrea Vedaldi. Interpretableexplanations of black boxes by meaningful pertur-bation. In Proceedings of the IEEE InternationalConference on Computer Vision, pages 3429–3437,2017.

[60] Alex Fout, Jonathon Byrd, Basir Shariat, and AsaBen-Hur. Protein interface prediction using graphconvolutional networks. In Advances in Neural Infor-mation Processing Systems, pages 6530–6539, 2017.

[61] Ferenc Galkó and Carsten Eickhoff. Biomedical ques-tion answering via weighted neural network passageretrieval. In European Conference on InformationRetrieval, pages 523–528. Springer, 2018.

[62] Yaroslav Ganin and Victor Lempitsky. Unsuper-vised domain adaptation by backpropagation. arXivpreprint arXiv:1409.7495, 2014.

[63] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan,Pascal Germain, Hugo Larochelle, François Lavi-olette, Mario Marchand, and Victor Lempitsky.Domain-adversarial training of neural networks. TheJournal of Machine Learning Research, 17(1):2096–2030, 2016.

[64] Leon A Gatys, Alexander S Ecker, and MatthiasBethge. Image style transfer using convolutionalneural networks. In Proceedings of the IEEE con-ference on computer vision and pattern recognition,pages 2414–2423, 2016.

[65] Amirata Ghorbani, Vivek Natarajan, David Coz,and Yuan Liu. Dermgan: Synthetic generation ofclinical skin images with pathology. arXiv preprintarXiv:1911.08716, 2019.

[66] Spyros Gidaris, Praveer Singh, and Nikos Ko-modakis.Unsupervised representation learningby predicting image rotations.arXiv preprintarXiv:1803.07728, 2018.

[67] Justin Gilmer, Samuel S Schoenholz, Patrick F Riley,Oriol Vinyals, and George E Dahl. Neural messagepassing for quantum chemistry. In Proceedings of the34th International Conference on Machine Learning-Volume 70, pages 1263–1272. JMLR. org, 2017.

[68] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,Bing Xu, David Warde-Farley, Sherjil Ozair, AaronCourville, and Yoshua Bengio. Generative adversar-ial nets. In Advances in neural information process-ing systems, pages 2672–2680, 2014.

[69] Priya Goyal, Dhruv Mahajan, Abhinav Gupta,and Ishan Misra. Scaling and benchmarking self-supervised visual representation learning.arXivpreprint arXiv:1905.01235, 2019.

[70] Alex Graves, Abdel-rahman Mohamed, and Geof-frey Hinton. Speech recognition with deep recurrentneural networks. In 2013 IEEE international con-ference on acoustics, speech and signal processing,pages 6645–6649. IEEE, 2013.

[71] Aditya Grover, Aaron Zweig, and Stefano Ermon.Graphite: Iterative generative modeling of graphs.arXiv preprint arXiv:1803.10459, 2018.

[72] Varun Gulshan, Lily Peng, Marc Coram, Martin CStumpe, Derek Wu, Arunachalam Narayanaswamy,Subhashini Venugopalan, Kasumi Widner, TomMadams, Jorge Cuadros, et al. Development and val-idation of a deep learning algorithm for detection ofdiabetic retinopathy in retinal fundus photographs.Jama, 316(22):2402–2410, 2016.

[73] Maryam Habibi, Leon Weber, Mariana Neves,David Luis Wiegandt, and Ulf Leser. Deep learningwith word embeddings improves biomedical namedentity recognition. Bioinformatics, 33(14):i37–i48,2017.

[74] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu,Miao Xu, Weihua Hu, Ivor Tsang, and MasashiSugiyama. Co-teaching: Robust training of deepneural networks with extremely noisy labels.InAdvances in neural information processing systems,pages 8527–8537, 2018.

[75] Ankur Handa, Michael Bloesch, Viorica Pătrăucean,Simon Stent, John McCormac, and Andrew Davi-son. gvnn: Neural network library for geometriccomputer vision. In European Conference on Com-puter Vision, pages 67–82. Springer, 2016.

[76] Boris Hanin. Which neural net architectures give riseto exploding and vanishing gradients? In Advancesin Neural Information Processing Systems, pages582–591, 2018.

[77] Jack Hanson, Yuedong Yang, Kuldip Paliwal, andYaoqi Zhou. Improving protein disorder predictionby deep bidirectional long short-term memory recur-rent neural networks. Bioinformatics, 33(5):685–692,2016.

[78] Kaiming He, Georgia Gkioxari, Piotr Dollár, andRoss Girshick. Mask r-cnn. In Proceedings of theIEEE international conference on computer vision,pages 2961–2969, 2017.

[79] Kaiming He, Xiangyu Zhang, Shaoqing Ren, andJian Sun. Deep residual learning for image recog-nition. In Proceedings of the IEEE conference oncomputer vision and pattern recognition, pages 770–778, 2016.

[80] Rhys Heffernan, Yuedong Yang, Kuldip Paliwal,and Yaoqi Zhou. Capturing non-local interactionsby long short-term memory bidirectional recurrentneural networks for improving prediction of pro-tein secondary structure, backbone angles, contactnumbers and solvent accessibility. Bioinformatics,33(18):2842–2849, 2017.

[81] Dan Hendrycks and Thomas Dietterich.Bench-marking neural network robustness to commoncorruptions and perturbations.arXiv preprintarXiv:1903.12261, 2019.

[82] Dan Hendrycks, Norman Mu, Ekin D Cubuk, BarretZoph, Justin Gilmer, and Balaji Lakshminarayanan.Augmix: A simple data processing method to im-prove robustness and uncertainty. arXiv preprintarXiv:1912.02781, 2019.

[83] Karl Moritz Hermann, Tomas Kocisky, EdwardGrefenstette, Lasse Espeholt, Will Kay, MustafaSuleyman, and Phil Blunsom. Teaching machinesto read and comprehend. In Advances in neuralinformation processing systems, pages 1693–1701,2015.

[84] R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, AdamTrischler, and Yoshua Bengio. Learning deep repre-sentations by mutual information estimation andmaximization.arXiv preprint arXiv:1808.06670,2018.

[85] Daniel Ho, Eric Liang, Ion Stoica, Pieter Abbeel,and Xi Chen. Population based augmentation: Ef-ficient learning of augmentation policy schedules.arXiv preprint arXiv:1905.05393, 2019.

[86] Jonathan Ho, Xi Chen, Aravind Srinivas, YanDuan, and Pieter Abbeel.Flow++: Improvingflow-based generative models with variational de-quantization and architecture design. arXiv preprintarXiv:1902.00275, 2019.

[87] Sepp Hochreiter. The vanishing gradient problemduring learning recurrent neural nets and problem so-lutions. International Journal of Uncertainty, Fuzzi-ness and Knowledge-Based Systems, 6(02):107–116,1998.

[88] Sepp Hochreiter and Jürgen Schmidhuber. Longshort-term memory. Neural computation, 9(8):1735–1780, 1997.

[89] Raphael Hoffmann, Congle Zhang, Xiao Ling, LukeZettlemoyer, and Daniel S Weld. Knowledge-basedweak supervision for information extraction of over-lapping relations. In Proceedings of the 49th AnnualMeeting of the Association for Computational Lin-guistics: Human Language Technologies-Volume 1,pages 541–550. Association for Computational Lin-guistics, 2011.

[90] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzeb-ski, Bruna Morrone, Quentin De Laroussilhe, An-drea Gesmundo, Mona Attariyan, and Sylvain Gelly.Parameter-efficient transfer learning for nlp. arXivpreprint arXiv:1902.00751, 2019.

[91] Andrew G Howard. Some improvements on deep con-volutional neural network based image classification.arXiv preprint arXiv:1312.5402, 2013.

[92] Jeremy Howard and Sebastian Ruder. Universallanguage model fine-tuning for text classification.arXiv preprint arXiv:1801.06146, 2018.

[93] Weihua Hu, Bowen Liu, Joseph Gomes, MarinkaZitnik, Percy Liang, Vijay Pande, and Jure Leskovec.Pre-training graph neural networks. arXiv preprintarXiv:1905.12265, 2019.

[94] Gao Huang, Zhuang Liu, Laurens Van Der Maaten,and Kilian Q Weinberger. Densely connected con-volutional networks. In Proceedings of the IEEEconference on computer vision and pattern recogni-tion, pages 4700–4708, 2017.

[95] Minyoung Huh, Pulkit Agrawal, and Alexei A Efros.What makes imagenet good for transfer learning?arXiv preprint arXiv:1608.08614, 2016.

[96] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, andAlexei A Efros. Image-to-image translation withconditional adversarial networks. In Proceedings ofthe IEEE conference on computer vision and patternrecognition, pages 1125–1134, 2017.

[97] Na Ji.Adaptive optical fluorescence microscopy.Nature methods, 14(4):374, 2017.

[98] Robin Jia and Percy Liang.Data recombina-tion for neural semantic parsing.arXiv preprintarXiv:1606.03622, 2016.

[99] Matthew Johnson,David K Duvenaud,AlexWiltschko, Ryan P Adams, and Sandeep R Datta.Composing graphical models with neural networksfor structured representations and fast inference. InAdvances in neural information processing systems,pages 2946–2954, 2016.

[100] Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative adversar-ial networks. In Proceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition, pages4401–4410, 2019.

[101] MF Kasim, D Watson-Parris, L Deaconu, S Oliver,P Hatfield, DH Froula, G Gregori, M Jarvis, S Khati-wala, J Korenaga, et al. Up to two billion times accel-eration of scientific simulations with deep neural ar-chitecture search. arXiv preprint arXiv:2001.08055,2020.

[102] Jeremy Kawahara, Sara Daneshvar, Giuseppe Argen-ziano, and Ghassan Hamarneh. Seven-point checklistand skin lesion classification using multitask multi-modal neural nets. IEEE journal of biomedical andhealth informatics, 23(2):538–546, 2018.

[103] Steven Kearnes, Kevin McCloskey, Marc Berndl,Vijay Pande, and Patrick Riley. Molecular graphconvolutions: moving beyond fingerprints. Journalof computer-aided molecular design, 30(8):595–608,2016.

[104] Been Kim, Martin Wattenberg, Justin Gilmer, Car-rie Cai, James Wexler, Fernanda Viegas, and RorySayres. Interpretability beyond feature attribution:Quantitative testing with concept activation vectors(tcav). arXiv preprint arXiv:1711.11279, 2017.

[105] Pieter-Jan Kindermans, Sara Hooker, Julius Ade-bayo, Maximilian Alber, Kristof T Schütt, SvenDähne, Dumitru Erhan, and Been Kim. The (un)reliability of saliency methods. In Explainable AI:Interpreting, Explaining and Visualizing Deep Learn-ing, pages 267–280. Springer, 2019.

[106] Pieter-Jan Kindermans, Kristof T Schütt, Maxim-ilian Alber, Klaus-Robert Müller, Dumitru Erhan,Been Kim, and Sven Dähne. Learning how to explainneural networks: Patternnet and patternattribution.arXiv preprint arXiv:1705.05598, 2017.

[107] D Kingma, Tim Salimans, R Josefowicz, Xi Chen,Ilya Sutskever, Max Welling, et al. Improving varia-tional autoencoders with inverse autoregressive flow.2017.

[108] Durk P Kingma and Prafulla Dhariwal. Glow: Gen-erative flow with invertible 1x1 convolutions. InAdvances in Neural Information Processing Systems,pages 10215–10224, 2018.

[109] Durk P Kingma, Shakir Mohamed, Danilo JimenezRezende, and Max Welling. Semi-supervised learn-ing with deep generative models. In Advances inneural information processing systems, pages 3581–3589, 2014.

[110] Sosuke Kobayashi. Contextual augmentation: Dataaugmentation by words with paradigmatic relations.arXiv preprint arXiv:1805.06201, 2018.

[111] Kaname Kojima, Shu Tadaka, Fumiki Katsuoka,Gen Tamiya, Masayuki Yamamoto, and Kengo Ki-noshita. A recurrent neural network based methodfor genotype imputation on phased genotype data.bioRxiv, page 821504, 2019.

[112] Alexander Kolesnikov, Xiaohua Zhai, and LucasBeyer. Revisiting self-supervised visual represen-tation learning. arXiv preprint arXiv:1901.09005,2019.

[113] Patrick T Komiske, Eric M Metodiev, and JesseThaler. Energy flow networks: deep sets for particlejets. Journal of High Energy Physics, 2019(1):121,2019.

[114] Shu Kong and Charless Fowlkes.Image recon-struction with predictive filter flow. arXiv preprintarXiv:1811.11482, 2018.

[115] Simon Kornblith, Mohammad Norouzi, HonglakLee, and Geoffrey Hinton.Similarity of neuralnetwork representations revisited. arXiv preprintarXiv:1905.00414, 2019.

[116] Simon Kornblith, Jonathon Shlens, and Quoc VLe. Do better imagenet models transfer better? InProceedings of the IEEE Conference on ComputerVision and Pattern Recognition, pages 2661–2671,2019.

[117] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hin-ton. Imagenet classification with deep convolutionalneural networks. In Advances in neural informationprocessing systems, pages 1097–1105, 2012.

[118] Sneha Reddy Kudugunta, Ankur Bapna, IsaacCaswell, Naveen Arivazhagan, and Orhan Firat. In-vestigating multilingual nmt representations at scale.arXiv preprint arXiv:1909.02197, 2019.

[119] Samuli Laine and Timo Aila.Temporal ensem-bling for semi-supervised learning. arXiv preprintarXiv:1610.02242, 2016.

[120] Dong-Hyun Lee.Pseudo-label: The simple andefficient semi-supervised learning method for deepneural networks.In Workshop on Challenges inRepresentation Learning, ICML, volume 3, page 2,2013.

[121] JinhyukLee,WonjinYoon,SungdongKim,Donghyeon Kim, Sunkyu Kim, Chan Ho So, and Jae-woo Kang. Biobert: pre-trained biomedical languagerepresentation model for biomedical text mining.arXiv preprint arXiv:1901.08746, 2019.

[122] Jaakko Lehtinen, Jacob Munkberg, Jon Hasselgren,Samuli Laine, Tero Karras, Miika Aittala, and TimoAila. Noise2noise: Learning image restoration with-out clean data. arXiv preprint arXiv:1803.04189,2018.

[123] Omer Levy and Yoav Goldberg. Neural word embed-ding as implicit matrix factorization. In Advances inneural information processing systems, pages 2177–2185, 2014.

[124] Chaolong Li, Zhen Cui, Wenming Zheng, ChunyanXu, and Jian Yang.Spatio-temporal graph con-volution for skeleton based action recognition. InThirty-Second AAAI Conference on Artificial Intel-ligence, 2018.

[125] Hailiang Li, Jian Weng, Yujian Shi, Wanrong Gu,Yijun Mao, Yonghua Wang, Weiwei Liu, and JiajieZhang. An improved deep learning approach fordetection of thyroid papillary cancer in ultrasoundimages. Scientific reports, 8(1):6600, 2018.

[126] Yixuan Li, Jason Yosinski, Jeff Clune, Hod Lipson,and John E Hopcroft.Convergent learning: Dodifferent neural networks learn the same representa-tions? In Iclr, 2016.

[127] Yujia Li, Daniel Tarlow, Marc Brockschmidt, andRichard Zemel. Gated graph sequence neural net-works. arXiv preprint arXiv:1511.05493, 2015.

[128] Timothy P Lillicrap, Jonathan J Hunt, Alexan-der Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa,David Silver, and Daan Wierstra. Continuous con-trol with deep reinforcement learning. arXiv preprintarXiv:1509.02971, 2015.

[129] Fang Liu, Zhaoye Zhou, Hyungseok Jang, AlexeySamsonov, Gengyan Zhao, and Richard Kijowski.Deep convolutional neural network and 3d de-formable approach for tissue segmentation in mus-culoskeletal magnetic resonance imaging. Magneticresonance in medicine, 79(4):2379–2391, 2018.

[130] Peter J Liu, Mohammad Saleh, Etienne Pot, BenGoodrich, Ryan Sepassi, Lukasz Kaiser, and NoamShazeer. Generating wikipedia by summarizing longsequences. arXiv preprint arXiv:1801.10198, 2018.

[131] Shengyu Liu, Buzhou Tang, Qingcai Chen, and Xiao-long Wang. Effects of semantic features on machinelearning-based drug name recognition systems: wordembeddings vs. manually constructed dictionaries.Information, 6(4):848–865, 2015.

[132] Xueliang Liu. Deep recurrent neural network forprotein function prediction from sequence. arXivpreprint arXiv:1701.08318, 2017.

[133] Yao Liu,Omer Gottesman,Aniruddh Raghu,Matthieu Komorowski, Aldo A Faisal, Finale Doshi-Velez, and Emma Brunskill. Representation bal-ancing mdps for off-policy policy evaluation.InAdvances in Neural Information Processing Systems,pages 2644–2653, 2018.

[134] Yao Liu, Adith Swaminathan, Alekh Agarwal,and Emma Brunskill.Off-policy policy gradientwith state distribution correction. arXiv preprintarXiv:1904.08473, 2019.

[135] Yun Liu, Krishna Gadepalli, Mohammad Norouzi,George E Dahl, Timo Kohlberger, Aleksey Boyko,Subhashini Venugopalan, Aleksei Timofeev, Philip QNelson, Greg S Corrado, et al. Detecting cancermetastases on gigapixel pathology images. arXivpreprint arXiv:1703.02442, 2017.

[136] Jonathan Long, Evan Shelhamer, and Trevor Darrell.Fully convolutional networks for semantic segmen-tation. In Proceedings of the IEEE conference oncomputer vision and pattern recognition, pages 3431–3440, 2015.

[137] Mingsheng Long, Han Zhu, Jianmin Wang, andMichael I Jordan.Deep transfer learning withjoint adaptation networks. In Proceedings of the34th International Conference on Machine Learning-Volume 70, pages 2208–2217. JMLR. org, 2017.

[138] Romain Lopez, Jeffrey Regier, Michael Cole, MichaelJordan, and Nir Yosef. A deep generative model forgene expression profiles from single-cell rna sequenc-ing. arXiv preprint arXiv:1709.02082, 2017.

[139] Donghuan Lu, Karteek Popuri, Gavin WeiguangDing, Rakesh Balachandar, and Mirza Faisal Beg.Multimodal and multiscale deep neural networksfor the early diagnosis of alzheimer’s disease usingstructural mr and fdg-pet images. Scientific reports,8(1):5697, 2018.

[140] Scott M Lundberg and Su-In Lee. A unified approachto interpreting model predictions. In Advances inNeural Information Processing Systems, pages 4765–4774, 2017.

[141] Laurens van der Maaten and Geoffrey Hinton. Visu-alizing data using t-sne. Journal of machine learningresearch, 9(Nov):2579–2605, 2008.

[142] Ali Madani, Bryan McCann, Nikhil Naik, Ni-tish Shirish Keskar, Namrata Anand, Raphael REguchi, Possu Huang, and Richard Socher. Progen:Language modeling for protein generation. bioRxiv,2020.

[143] Dhruv Mahajan,Ross Girshick,Vignesh Ra-manathan, Kaiming He, Manohar Paluri, YixuanLi, Ashwin Bharambe, and Laurens van der Maaten.Exploring the limits of weakly supervised pretrain-ing. In Proceedings of the European Conference onComputer Vision (ECCV), pages 181–196, 2018.

[144] Hongzi Mao, Parimarjan Negi, Akshay Narayan,Hanrui Wang, Jiacheng Yang, Haonan Wang, RyanMarcus, Ravichandra Addanki, Mehrdad Khani,Songtao He, et al.Park: An open platform forlearning augmented computer systems. 2019.

[145] Daniel L Marino, Kasun Amarasinghe, and MilosManic. Building energy load forecasting using deepneural networks. In IECON 2016-42nd Annual Con-ference of the IEEE Industrial Electronics Society,pages 7046–7051. IEEE, 2016.

[146] Alexander Mathis, Pranav Mamidanna, Kevin MCury, Taiga Abe, Venkatesh N Murthy, Macken-zieWeygandtMathis,andMatthiasBethge.Deeplabcut:markerless pose estimation of user-defined body parts with deep learning. Nature neu-roscience, 21(9):1281, 2018.

[147] Mackenzie Weygandt Mathis and Alexander Mathis.Deep learning tools for the measurement of animalbehavior in neuroscience. Current Opinion in Neu-robiology, 60:1–11, 2020.

[148] Leland McInnes, John Healy, and James Melville.Umap: Uniform manifold approximation and pro-jection for dimension reduction.arXiv preprintarXiv:1802.03426, 2018.

[149] Stephen Merity, Nitish Shirish Keskar, and RichardSocher. Regularizing and Optimizing LSTM Lan-guage Models.arXiv preprint arXiv:1708.02182,2017.

[150] Stephen Merity, Nitish Shirish Keskar, and RichardSocher. An Analysis of Neural Language Modelingat Multiple Scales. arXiv preprint arXiv:1803.08240,2018.

[151] Tomas Mikolov, Kai Chen, Greg Corrado, andJeffrey Dean.Efficient estimation of word rep-resentations in vector space.arXiv preprintarXiv:1301.3781, 2013.

[152] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg SCorrado, and Jeff Dean. Distributed representationsof words and phrases and their compositionality. InAdvances in neural information processing systems,pages 3111–3119, 2013.

[153] Mike Mintz, Steven Bills, Rion Snow, and Dan Ju-rafsky. Distant supervision for relation extractionwithout labeled data. In Proceedings of the JointConference of the 47th Annual Meeting of the ACLand the 4th International Joint Conference on Nat-ural Language Processing of the AFNLP: Volume2-Volume 2, pages 1003–1011. Association for Com-putational Linguistics, 2009.

[154] Ishan Misra and Laurens van der Maaten. Self-supervised learning of pretext-invariant representa-tions, 2019.

[155] Takeru Miyato, Shin-ichi Maeda, Masanori Koyama,and Shin Ishii.Virtual adversarial training:aregularization method for supervised and semi-supervised learning. IEEE transactions on patternanalysis and machine intelligence, 41(8):1979–1993,2018.

[156] Pim Moeskops, Max A Viergever, Adriënne M Men-drik, Linda S de Vries, Manon JNL Benders, andIvana Išgum. Automatic segmentation of mr brainimages with a convolutional neural network. IEEEtransactions on medical imaging, 35(5):1252–1261,2016.

[157] Ari Morcos, Maithra Raghu, and Samy Bengio. In-sights on representational similarity in neural net-works with canonical correlation. In Advances inNeural Information Processing Systems, pages 5727–5736, 2018.

[158] Alejandro Newell, Kaiyu Yang, and Jia Deng.Stacked hourglass networks for human pose esti-mation. In European conference on computer vision,pages 483–499. Springer, 2016.

[159] Jiquan Ngiam, Daiyi Peng, Vijay Vasudevan, SimonKornblith, Quoc V Le, and Ruoming Pang. Domainadaptive transfer learning with specialist models.arXiv preprint arXiv:1811.07056, 2018.

[160] Harsha Nori, Samuel Jenkins, Paul Koch, and RichCaruana.Interpretml: A unified framework formachine learning interpretability. arXiv preprintarXiv:1909.09223, 2019.

[161] Mehdi Noroozi and Paolo Favaro.Unsupervisedlearning of visual representations by solving jigsawpuzzles. In European Conference on Computer Vi-sion, pages 69–84. Springer, 2016.

[162] Luke Oakden-Rayner, Jared Dunnmon, GustavoCarneiro, and Christopher Ré. Hidden stratifica-tion causes clinically meaningful failures in ma-chine learning for medical imaging. arXiv preprintarXiv:1909.12475, 2019.

[163] Chris Olah.Understanding LSTM Networks,2015.https://colah.github.io/posts/2015-08-Understanding-LSTMs/.

[164] Chris Olah, Nick Cammarata, Ludwig Schubert,Gabriel Goh, Michael Petrov, and Shan Carter.Zoom in:An introduction to circuits.Distill,5(3):e00024–001, 2020.

[165] Chris Olah, Alexander Mordvintsev, and LudwigSchubert.Feature visualization.Distill, 2017.https://distill.pub/2017/feature-visualization.

[166] ChrisOlah,ArvindSatyanarayan,IanJohn-son, Shan Carter, Ludwig Schubert, KatherineYe,and Alexander Mordvintsev.The build-ingblocksofinterpretability.Distill,2018.https://distill.pub/2018/building-blocks.

[167] Aaron van den Oord, Sander Dieleman, HeigaZen, Karen Simonyan, Oriol Vinyals, Alex Graves,Nal Kalchbrenner, Andrew Senior, and KorayKavukcuoglu.Wavenet: A generative model forraw audio. arXiv preprint arXiv:1609.03499, 2016.

[168] Aaron van den Oord, Nal Kalchbrenner, and KorayKavukcuoglu. Pixel recurrent neural networks. arXivpreprint arXiv:1601.06759, 2016.

[169] Aaron van den Oord, Yazhe Li, and Oriol Vinyals.Representation learning with contrastive predictivecoding. arXiv preprint arXiv:1807.03748, 2018.

[170] Razvan Pascanu, Tomas Mikolov, and Yoshua Ben-gio. Understanding the exploding gradient problem.CoRR, abs/1211.5063, 2, 2012.

[171] Deepak Pathak, Philipp Krahenbuhl, and TrevorDarrell. Constrained convolutional neural networksfor weakly supervised segmentation. In Proceedingsof the IEEE international conference on computervision, pages 1796–1804, 2015.

[172] Romain Paulus, Caiming Xiong, and Richard Socher.A deep reinforced model for abstractive summariza-tion. arXiv preprint arXiv:1705.04304, 2017.

[173] Jeffrey Pennington, Richard Socher, and Christo-pher Manning. Glove: Global vectors for word rep-resentation. In Proceedings of the 2014 conferenceon empirical methods in natural language processing(EMNLP), pages 1532–1543, 2014.

[174] Hieu Pham, Melody Y Guan, Barret Zoph, Quoc VLe, and Jeff Dean.Efficient neural architecturesearch via parameter sharing.arXiv preprintarXiv:1802.03268, 2018.

[175] Gianluca Pollastri, Darisz Przybylski, BurkhardRost, and Pierre Baldi. Improving the predictionof protein secondary structure in three and eightclasses using recurrent neural networks and profiles.Proteins: Structure, Function, and Bioinformatics,47(2):228–235, 2002.

[176] Ryan Poplin, Avinash V Varadarajan, Katy Blumer,Yun Liu, Michael V McConnell, Greg S Corrado,Lily Peng, and Dale R Webster. Prediction of cardio-vascular risk factors from retinal fundus photographsvia deep learning. Nature Biomedical Engineering,2(3):158, 2018.

[177] Rory M Power and Jan Huisken. A guide to light-sheet fluorescence microscopy for multiscale imaging.Nature methods, 14(4):360, 2017.

[178] Doina Precup. Eligibility traces for off-policy policyevaluation. Computer Science Department FacultyPublication Series, page 80, 2000.

[179] Siyuan Qiao, Wei Shen, Zhishuai Zhang, Bo Wang,and Alan Yuille.Deep co-training for semi-supervised image recognition. In Proceedings of theEuropean Conference on Computer Vision (ECCV),pages 135–152, 2018.

[180] Alec Radford, Jeffrey Wu, Rewon Child, David Luan,Dario Amodei, and Ilya Sutskever. Language modelsare unsupervised multitask learners. OpenAI Blog,1(8), 2019.

[181] Colin Raffel, Noam Shazeer, Adam Roberts, Kather-ine Lee, Sharan Narang, Michael Matena, YanqiZhou, Wei Li, and Peter J Liu. Exploring the lim-its of transfer learning with a unified text-to-texttransformer. arXiv preprint arXiv:1910.10683, 2019.

[182] Aniruddh Raghu, Matthieu Komorowski, Leo An-thony Celi, Peter Szolovits, and Marzyeh Ghassemi.Continuous state-space models for optimal sepsistreatment-a deep reinforcement learning approach.arXiv preprint arXiv:1705.08422, 2017.

[183] Maithra Raghu, Justin Gilmer, Jason Yosinski, andJascha Sohl-Dickstein. Svcca: Singular vector canon-ical correlation analysis for deep learning dynamicsand interpretability. In Advances in Neural Infor-mation Processing Systems, pages 6076–6085, 2017.

[184] Maithra Raghu, Chiyuan Zhang, Jon Kleinberg, andSamy Bengio. Transfusion: Understanding transferlearning for medical imaging. In Advances in NeuralInformation Processing Systems, pages 3342–3352,2019.

[185] Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Bran-don Yang, Hershel Mehta, Tony Duan, Daisy Ding,Aarti Bagul, Curtis Langlotz, Katie Shpanskaya,et al.Chexnet: Radiologist-level pneumonia de-tection on chest x-rays with deep learning. arXivpreprint arXiv:1711.05225, 2017.

[186] Pranav Rajpurkar, Jian Zhang, Konstantin Lopy-rev, and Percy Liang. Squad: 100,000+ questionsfor machine comprehension of text. arXiv preprintarXiv:1606.05250, 2016.

[187] Bharath Ramsundar, Steven Kearnes, Patrick Riley,Dale Webster, David Konerding, and Vijay Pande.Massively multitask networks for drug discovery.arXiv preprint arXiv:1502.02072, 2015.

[188] Alexander Ratner, Stephen H Bach, Henry Ehren-berg, Jason Fries, Sen Wu, and Christopher Ré.Snorkel: Rapid training data creation with weaksupervision. Proceedings of the VLDB Endowment,11(3):269–282, 2017.

[189] Ali Razavi, Aaron van den Oord, and Oriol Vinyals.Generating diverse high-fidelity images with vq-vae-2. arXiv preprint arXiv:1906.00446, 2019.

[190] Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt,and Vaishaal Shankar. Do imagenet classifiers gener-alize to imagenet? arXiv preprint arXiv:1902.10811,2019.

[191] JosephRedmonandAliFarhadi.Yolov3:An incremental improvement.arXiv preprintarXiv:1804.02767, 2018.

[192] Shaoqing Ren, Kaiming He, Ross Girshick, and JianSun. Faster r-cnn: Towards real-time object detec-tion with region proposal networks. In Advances inneural information processing systems, pages 91–99,2015.

[193] Donatas Repecka, Vykintas Jauniskis, LaurynasKarpus, Elzbieta Rembeza, Jan Zrimec, SimonaPoviloniene, Irmantas Rokaitis, Audrius Laurynenas,Wissam Abuajwa, Otto Savolainen, et al. Expandingfunctional protein sequence space using generativeadversarial networks. bioRxiv, page 789719, 2019.

[194] Marco Tulio Ribeiro, Sameer Singh, and CarlosGuestrin.Why should i trust you?: Explainingthe predictions of any classifier. In Proceedings ofthe 22nd ACM SIGKDD international conference onknowledge discovery and data mining, pages 1135–1144. ACM, 2016.

[195] Alexander Rives, Siddharth Goyal, Joshua Meier,Demi Guo, Myle Ott, C Lawrence Zitnick, Jerry Ma,and Rob Fergus. Biological structure and functionemerge from scaling unsupervised learning to 250million protein sequences.bioRxiv, page 622803,2019.

[196] Olaf Ronneberger, Philipp Fischer, and ThomasBrox. U-net: Convolutional networks for biomedicalimage segmentation. In International Conferenceon Medical image computing and computer-assistedintervention, pages 234–241. Springer, 2015.

[197] Alexander M Rush, Sumit Chopra, and JasonWeston.A neural attention model for abstrac-tive sentence summarization.arXiv preprintarXiv:1509.00685, 2015.

[198] Andrei A Rusu, Mel Vecerik, Thomas Rothörl, Nico-las Heess, Razvan Pascanu, and Raia Hadsell. Sim-to-real robot learning from pixels with progressivenets. arXiv preprint arXiv:1610.04286, 2016.

[199] Ruhan Sa, William Owens, Raymond Wiegand,Mark Studin, Donald Capoferri, Kenneth Barooha,Alexander Greaux, Robert Rattray, Adam Hutton,John Cintineo, et al. Intervertebral disc detectionin x-ray images using faster r-cnn. In 2017 39thAnnual International Conference of the IEEE Engi-neering in Medicine and Biology Society (EMBC),pages 564–567. IEEE, 2017.

[200] Tim Salimans, Andrej Karpathy, Xi Chen, andDiederik P Kingma. Pixelcnn++: Improving thepixelcnn with discretized logistic mixture likeli-hood and other modifications.arXiv preprintarXiv:1701.05517, 2017.

[201] Victor Sanh, Lysandre Debut, Julien Chaumond,and Thomas Wolf. Distilbert, a distilled versionof bert: smaller, faster, cheaper and lighter. arXivpreprint arXiv:1910.01108, 2019.

[202] Saman Sarraf, Ghassem Tofighi, et al.Deepad:Alzheimer disease classification via deep convolu-tional neural networks using mri and fmri. BioRxiv,page 070441, 2016.

[203] John Schulman, Filip Wolski,Prafulla Dhari-wal, Alec Radford, and Oleg Klimov.Proximalpolicy optimization algorithms.arXiv preprintarXiv:1707.06347, 2017.

[204] Ramprasaath R Selvaraju, Michael Cogswell, Ab-hishek Das, Ramakrishna Vedantam, Devi Parikh,and Dhruv Batra. Grad-cam: Visual explanationsfrom deep networks via gradient-based localization.In Proceedings of the IEEE International Conferenceon Computer Vision, pages 618–626, 2017.

[205] Andrew W Senior, Richard Evans, John Jumper,James Kirkpatrick, Laurent Sifre, Tim Green,Chongli Qin, Augustin Žídek, Alexander WR Nelson,Alex Bridgland, et al. Improved protein structureprediction using potentials from deep learning. Na-ture, pages 1–5, 2020.

[206] Rico Sennrich, Barry Haddow, and Alexandra Birch.Improving neural machine translation models withmonolingual data. arXiv preprint arXiv:1511.06709,

[207] Lloyd S Shapley. A value for n-person games. Con-tributions to the Theory of Games, 2(28):307–317,1953.

[208] Jianghong Shi, Eric Shea-Brown, and Michael Buice.Comparison against task driven artificial neural net-works reveals functional properties in mouse visualcortex. In Advances in Neural Information Process-ing Systems, pages 5765–5775, 2019.

[209] Susan M Shortreed, Eric Laber, Daniel J Lizotte,T Scott Stroup, Joelle Pineau, and Susan A Mur-phy. Informing sequential clinical decision-makingthrough reinforcement learning: an empirical study.Machine learning, 84(1-2):109–136, 2011.

[210] Avanti Shrikumar, Peyton Greenside, and AnshulKundaje. Learning important features through prop-agating activation differences. In Proceedings of the34th International Conference on Machine Learning-Volume 70, pages 3145–3153. JMLR. org, 2017.

[211] Rui Shu, Hung H Bui, Hirokazu Narui, and StefanoErmon. A dirt-t approach to unsupervised domainadaptation. arXiv preprint arXiv:1802.08735, 2018.

[212] David Silver, Julian Schrittwieser, Karen Simonyan,Ioannis Antonoglou, Aja Huang, Arthur Guez,Thomas Hubert, Lucas Baker, Matthew Lai, AdrianBolton, et al. Mastering the game of go withouthuman knowledge. nature, 550(7676):354–359, 2017.

[213] Karen Simonyan, Andrea Vedaldi, and Andrew Zis-serman. Deep inside convolutional networks: Visual-ising image classification models and saliency maps.arXiv preprint arXiv:1312.6034, 2013.

[214] Karen Simonyan and Andrew Zisserman. Very deepconvolutional networks for large-scale image recog-nition. arXiv preprint arXiv:1409.1556, 2014.

[215] Daniel Smilkov, Nikhil Thorat, Been Kim, Fer-nanda Viégas, and Martin Wattenberg. Smooth-grad: removing noise by adding noise. arXiv preprintarXiv:1706.03825, 2017.

[216] Casper Kaae Sønderby, Tapani Raiko, Lars Maaløe,Søren Kaae Sønderby, and Ole Winther. Laddervariational autoencoders.In Advances in neuralinformation processing systems, pages 3738–3746,2016.

[217] Youyi Song, Ling Zhang, Siping Chen, Dong Ni,Baopu Li, Yongjing Zhou, Baiying Lei, and TianfuWang. A deep learning based framework for accuratesegmentation of cervical cytoplasm and nuclei. In2014 36th Annual International Conference of theIEEE Engineering in Medicine and Biology Society,pages 2903–2906. IEEE, 2014.

[218] Ke Sun, Bin Xiao, Dong Liu, and Jingdong Wang.Deep high-resolution representation learning for hu-man pose estimation. In Proceedings of the IEEEConference on Computer Vision and Pattern Recog-nition, pages 5693–5703, 2019.

[219] Yu Sun, Eric Tzeng, Trevor Darrell, and Alexei AEfros. Unsupervised domain adaptation throughself-supervision. arXiv preprint arXiv:1909.11825,2019.

[220] Mukund Sundararajan, Ankur Taly, and Qiqi Yan.Axiomatic attribution for deep networks. In Proceed-ings of the 34th International Conference on Ma-chine Learning-Volume 70, pages 3319–3328. JMLR.org, 2017.

[221] I Sutskever, O Vinyals, and QV Le. Sequence tosequence learning with neural networks. Advancesin NIPS, 2014.

[222] Ryo Takahashi, Takashi Matsubara, and KuniakiUehara. Data augmentation using random imagecropping and patching for deep cnns. IEEE Transac-tions on Circuits and Systems for Video Technology,2019.

[223] Mingxing Tan and Quoc V Le. Efficientnet: Rethink-ing model scaling for convolutional neural networks.arXiv preprint arXiv:1905.11946, 2019.

[224] Mingxing Tan, Ruoming Pang, and Quoc V Le.Efficientdet: Scalable and efficient object detection.arXiv preprint arXiv:1911.09070, 2019.

[225] Antti Tarvainen and Harri Valpola. Mean teachersare better role models: Weight-averaged consistencytargets improve semi-supervised deep learning re-sults. In Advances in neural information processingsystems, pages 1195–1204, 2017.

[226] Dimitry Tegunov and Patrick Cramer. Real-timecryo-em data pre-processing with warp. BioRxiv,page 338558, 2018.

[227] Yee Liang Thian, Yiting Li, Pooja Jagmohan, DavidSia, Vincent Ern Yao Chan, and Robby T Tan. Con-volutional neural networks for automated fracturedetection and localization on wrist radiographs. Ra-diology: Artificial Intelligence, 1(1):e180001, 2019.

[228] Eric J Topol. High-performance medicine: the con-vergence of human and artificial intelligence. Naturemedicine, 25(1):44–56, 2019.

[229] Raphael Townshend, Rishi Bedi, Patricia Suriana,and Ron Dror. End-to-end learning on 3d proteinstructure for interface prediction. In Advances inNeural Information Processing Systems, pages 15616–15625, 2019.

[230] Vahe Tshitoyan, John Dagdelen, Leigh Weston,Alexander Dunn, Ziqin Rong, Olga Kononova,Kristin A Persson, Gerbrand Ceder, and AnubhavJain. Unsupervised word embeddings capture latentknowledge from materials science literature. Nature,571(7763):95–98, 2019.

[231] Kensuke Umehara, Junko Ota, and Takayuki Ishida.Application of super-resolution convolutional neuralnetwork for enhancing image resolution in chest ct.Journal of digital imaging, 31(4):441–450, 2018.

[232] Aaron Van den Oord, Nal Kalchbrenner, Lasse Es-peholt, Oriol Vinyals, Alex Graves, et al. Condi-tional image generation with pixelcnn decoders. InAdvances in neural information processing systems,pages 4790–4798, 2016.

[233] Ashish Vaswani, Noam Shazeer, Niki Parmar, JakobUszkoreit, Llion Jones, Aidan N Gomez, ŁukaszKaiser, and Illia Polosukhin. Attention is all youneed. In Advances in neural information processingsystems, pages 5998–6008, 2017.

[234] Oriol Vinyals and Quoc Le. A neural conversationalmodel. arXiv preprint arXiv:1506.05869, 2015.

[235] Elena Voita, Rico Sennrich, and Ivan Titov. Thebottom-up evolution of representations in the trans-former:A study with machine translation andlanguage modeling objectives.arXiv preprintarXiv:1909.01380, 2019.

[236] Christian Wachinger, Martin Reuter, and TassiloKlein. Deepnat: Deep convolutional neural networkfor segmenting neuroanatomy. NeuroImage, 170:434–445, 2018.

[237] Kun Wang, Bite Yang, Guohai Xu, and XiaofengHe. Medical question retrieval based on siameseneural network and transfer learning method. InInternational Conference on Database Systems forAdvanced Applications, pages 49–64. Springer, 2019.

[238] Nancy XR Wang, Ali Farhadi, Rajesh PN Rao, andBingni W Brunton. Ajile movement prediction: Mul-timodal deep learning for natural human neuralrecordings and video. In Thirty-Second AAAI Con-ference on Artificial Intelligence, 2018.

[239] William Yang Wang and Diyi Yang. That’s so an-noying!!!: A lexical and frame-semantic embeddingbased data augmentation approach to automatic cat-egorization of annoying behaviors using# petpeevetweets. In Proceedings of the 2015 Conference onEmpirical Methods in Natural Language Processing,pages 2557–2563, 2015.

[240] Xiaolong Wang, Ross Girshick, Abhinav Gupta, andKaiming He. Non-local neural networks. In Proceed-ings of the IEEE Conference on Computer Visionand Pattern Recognition, pages 7794–7803, 2018.

[241] Zeyu Wang, Klint Qinami, Yannis Karakozis, KyleGenova, Prem Nair, Kenji Hata, and Olga Rus-sakovsky. Towards fairness in visual recognition: Ef-fective strategies for bias mitigation. arXiv preprintarXiv:1911.11834, 2019.

[242] Ziyu Wang, Victor Bapst, Nicolas Heess, VolodymyrMnih, Remi Munos, Koray Kavukcuoglu, and Nandode Freitas. Sample efficient actor-critic with experi-ence replay. arXiv preprint arXiv:1611.01224, 2016.

[243] Jason W Wei and Kai Zou. Eda: Easy data augmen-tation techniques for boosting performance on textclassification tasks. arXiv preprint arXiv:1901.11196,2019.

[244] Shih-En Wei, Varun Ramakrishna, Takeo Kanade,and Yaser Sheikh. Convolutional pose machines. InProceedings of the IEEE Conference on ComputerVision and Pattern Recognition, pages 4724–4732,2016.

[245] Martin Weigert, Uwe Schmidt, Tobias Boothe, An-dreas Müller, Alexandr Dibrov, Akanksha Jain, Ben-jamin Wilhelm, Deborah Schmidt, Coleman Broad-dus, Siân Culley, et al. Content-aware image restora-tion: pushing the limits of fluorescence microscopy.Nature methods, 15(12):1090, 2018.

[246] David Weiss, Chris Alberti, Michael Collins, andSlav Petrov.Structured training for neural net-work transition-based parsing.arXiv preprintarXiv:1506.06158, 2015.

[247] Julia K Winkler, Christine Fink, Ferdinand Toberer,Alexander Enk, Teresa Deinlein, Rainer Hofmann-Wellenhof, Luc Thomas, Aimilios Lallas, AndreasBlum, Wilhelm Stolz, et al. Association betweensurgical skin markings in dermoscopic images anddiagnostic performance of a deep learning convo-lutional neural network for melanoma recognition.JAMA dermatology, 155(10):1135–1141, 2019.

[248] Yuxin Wu, Alexander Kirillov, Francisco Massa,Wan-YenLo,andRossGirshick.Detec-tron2.https://github.com/facebookresearch/detectron2, 2019.

[249] Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg,Joseph Gomes, Caleb Geniesse, Aneesh S Pappu,Karl Leswing, and Vijay Pande. Moleculenet: abenchmark for molecular machine learning. Chemi-cal science, 9(2):513–530, 2018.

[250] Zonghan Wu, Shirui Pan, Fengwen Chen, GuodongLong, Chengqi Zhang, and Philip S Yu. A com-prehensive survey on graph neural networks. arXivpreprint arXiv:1901.00596, 2019.

[251] Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-ThangLuong, and Quoc V Le. Unsupervised data augmen-tation. arXiv preprint arXiv:1904.12848, 2019.

[252] Qizhe Xie, Eduard Hovy, Minh-Thang Luong, andQuoc V Le.Self-training with noisy studentimproves imagenet classification.arXiv preprintarXiv:1911.04252, 2019.

[253] Saining Xie, Ross Girshick, Piotr Dollár, ZhuowenTu, and Kaiming He. Aggregated residual transfor-mations for deep neural networks. In Proceedings ofthe IEEE conference on computer vision and patternrecognition, pages 1492–1500, 2017.

[254] Jun Xu, Xiaofei Luo, Guanhao Wang, HannahGilmore, and Anant Madabhushi. A deep convolu-tional neural network for segmenting and classifyingepithelial and stromal regions in histopathologicalimages. Neurocomputing, 191:214–223, 2016.

[255] Xueting Yan, Ishan Misra, Abhinav Gupta, DeeptiGhadiyaram, and Dhruv Mahajan. Clusterfit: Im-proving generalization of visual representations.arXiv preprint arXiv:1912.03330, 2019.

[256] Yilong Yang, Zhuyifan Ye, Yan Su, Qianqian Zhao,Xiaoshan Li, and Defang Ouyang. Deep learning forin vitro prediction of pharmaceutical formulations.Acta pharmaceutica sinica B, 9(1):177–185, 2019.

[257] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-bonell, Ruslan Salakhutdinov, and Quoc V Le. Xlnet:Generalized autoregressive pretraining for languageunderstanding. arXiv preprint arXiv:1906.08237,2019.

[258] Koichiro Yasaka, Hiroyuki Akai, Osamu Abe, andShigeru Kiryu. Deep learning with convolutionalneural network for differentiation of liver masses atdynamic contrast-enhanced ct: a preliminary study.Radiology, 286(3):887–896, 2017.

[259] Jason Yosinski, Jeff Clune, Anh Nguyen, ThomasFuchs, and Hod Lipson. Understanding neural net-works through deep visualization. arXiv preprintarXiv:1506.06579, 2015.

[260] Yuhui Yuan, Xilin Chen, and Jingdong Wang.Object-contextual representations for semantic seg-mentation. arXiv preprint arXiv:1909.11065, 2019.

[261] Sangdoo Yun, Dongyoon Han, Seong Joon Oh,Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo.Cutmix: Regularization strategy to train strong clas-sifiers with localizable features. In Proceedings ofthe IEEE International Conference on ComputerVision, pages 6023–6032, 2019.

[262] Manzil Zaheer, Satwik Kottur, Siamak Ravan-bakhsh, Barnabas Poczos, Russ R Salakhutdinov,and Alexander J Smola. Deep sets. In Advances inneural information processing systems, pages 3391–3401, 2017.

[263] Matthew D Zeiler and Rob Fergus.Visualizingand understanding convolutional networks. In Euro-pean conference on computer vision, pages 818–833.Springer, 2014.

[264] Daojian Zeng, Kang Liu, Yubo Chen, and Jun Zhao.Distant supervision for relation extraction via piece-wise convolutional neural networks. In Proceedingsof the 2015 Conference on Empirical Methods in Nat-ural Language Processing, pages 1753–1762, 2015.

[265] XiaohuaZhai,AvitalOliver,AlexanderKolesnikov,andLucasBeyer.S4l:Self-supervisedsemi-supervisedlearning.arXivpreprint arXiv:1905.03670, 2019.

[266] XiaohuaZhai,JoanPuigcerver,AlexanderKolesnikov,Pierre Ruyssen,Carlos Riquelme,Mario Lucic, Josip Djolonga, Andre Susano Pinto,Maxim Neumann, Alexey Dosovitskiy, et al. Thevisual task adaptation benchmark. arXiv preprintarXiv:1910.04867, 2019.

[267] Aston Zhang, Zachary C Lipton, Mu Li, and Alexan-der J Smola. Dive into deep learning. Unpublisheddraft. Retrieved, 3:319, 2019.

[268] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin,and David Lopez-Paz. mixup: Beyond empiricalrisk minimization. arXiv preprint arXiv:1710.09412,2017.

[269] Junkang Zhang, Haigen Hu, Shengyong Chen, Yu-jiao Huang, and Qiu Guan. Cancer cells detectionin phase-contrast microscopy images based on fasterr-cnn.In 2016 9th International Symposium onComputational Intelligence and Design (ISCID), vol-ume 1, pages 363–367. IEEE, 2016.

[270] Yulun Zhang, Yapeng Tian, Yu Kong, Bineng Zhong,and Yun Fu. Residual dense network for image super-resolution. In Proceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition, pages2472–2481, 2018.

[271] Victor Zhong, Caiming Xiong, and Richard Socher.Seq2sql: Generating structured queries from natu-ral language using reinforcement learning. arXivpreprint arXiv:1709.00103, 2017.

[272] Bolei Zhou,Aditya Khosla,Agata Lapedriza,Aude Oliva, and Antonio Torralba. Object detec-tors emerge in deep scene cnns.arXiv preprintarXiv:1412.6856, 2014.

[273] Qingyu Zhou, Nan Yang, Furu Wei, Shaohan Huang,Ming Zhou, and Tiejun Zhao. Neural documentsummarization by jointly learning to score and selectsentences. arXiv preprint arXiv:1807.02305, 2018.

[274] Jun-Yan Zhu, Taesung Park, Phillip Isola, andAlexei A Efros.Unpaired image-to-image trans-lation using cycle-consistent adversarial networks.In Proceedings of the IEEE international conferenceon computer vision, pages 2223–2232, 2017.

[275] Luisa M Zintgraf, Taco S Cohen, Tameem Adel, andMax Welling. Visualizing deep neural network deci-sions: Prediction difference analysis. arXiv preprintarXiv:1702.04595, 2017.
